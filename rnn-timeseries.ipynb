{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rnn-timeseries","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNnKdbB0weXrmVPTcHbPqga"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Sd_7tU-W69oF","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","%load_ext tensorboard"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8HwqipWWGiJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnGXCsSw7FRR","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from absl import logging\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fanXGQc8gri","colab_type":"code","colab":{}},"source":["def plot_series(time, series, format=\"-\", start=0, end=None,color='blue'):\n","    plt.plot(time[start:end], series[start:end], format,color=color)\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"Value\")\n","    plt.grid(True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1owvcpw48DSP","colab_type":"code","colab":{}},"source":["def trend(time, slope=0):\n","    return slope * time\n","\n","time = np.arange(4 * 365 + 1, dtype=\"float32\")\n","baseline = 10\n","slope = 0.03\n","series = trend(time, 0.1)  \n","\n","plot_series(time,series)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_WWWjswp8_fw","colab_type":"code","colab":{}},"source":["def seasonal_pattern(season_time):\n","    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n","    return np.where(season_time < 0.4,\n","                    np.cos(season_time * 2 * np.pi),\n","                    1 / np.exp(3 * season_time))\n","\n","def seasonality(time, period, amplitude=1, phase=0):\n","    \"\"\"Repeats the same pattern at each period\"\"\"\n","    season_time = ((time + phase) % period) / period\n","    return amplitude * seasonal_pattern(season_time)\n","\n","\n","baseline = 10\n","amplitude = 20\n","\n","# Create the series\n","series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n","\n","plot_series(time,series)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXzyhh3K7OLm","colab_type":"code","colab":{}},"source":["\n","def noise(time, noise_level=1, seed=None):\n","    rnd = np.random.RandomState(seed)\n","    return rnd.randn(len(time)) * noise_level\n","\n","noise_level = 2\n","\n","\n","# Update with noise\n","series += noise(time, noise_level, seed=42)\n","\n","plot_series(time, series)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TguhSdf9lVD","colab_type":"code","colab":{}},"source":["split_time = 1000\n","time_train = time[:split_time]\n","x_train = series[:split_time]\n","time_test = time[split_time:]\n","x_test = series[split_time:]\n","train_nb = x_train.shape[0]\n","test_nb = x_test.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qN37U_167UBb","colab_type":"code","colab":{}},"source":["def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","  dataset = tf.data.Dataset.from_tensor_slices(series)\n","  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n","  #print(\"window:\",list(next(iter(dataset)).as_numpy_iterator()) )\n","  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))  \n","  #print(\"flat_map:\",list(dataset.as_numpy_iterator()) )\n","  #dataset = dataset.map(lambda window: tf.expand_dims(window, axis=-1))\n","  #print(\"expanded map:\",list(dataset.as_numpy_iterator()) )\n","\n","  dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n","  print(\"map:\",list(dataset.as_numpy_iterator()) )\n","\n","  dataset = dataset.shuffle(shuffle_buffer)\n","  dataset = dataset.batch(batch_size,drop_remainder=True)\n","  return dataset\n","\n","tmp_x= np.array([1,3,2,4,6,2,1,1,2,1,6,7,2,4,6],dtype=np.float32 )\n","tmp_set = windowed_dataset(tmp_x, window_size=3, batch_size=4, shuffle_buffer=15)\n","#iter = iter(tmp_set)\n","#next(iter)#, next(iter) \n","next(iter(tmp_set))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NfpkL8uhBCZ3","colab_type":"code","colab":{}},"source":["window_size = 20\n","batch_size = 32\n","\n","\n","train_ds = windowed_dataset(x_train, window_size, batch_size=128, shuffle_buffer= train_nb)\n","test_ds = windowed_dataset(x_test, window_size, batch_size=128, shuffle_buffer= test_nb)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uRiLpZb8G7pU","colab_type":"text"},"source":["RNN model\n","\n","![Texte alternatifâ€¦](https://miro.medium.com/max/2944/1*obLEYSKh2nytc2Hu344psw.png)\n"]},{"cell_type":"code","metadata":{"id":"VBmXH75dB-2I","colab_type":"code","colab":{}},"source":["tf.random.set_seed(1)\n","np.random.seed=1\n","def get_normal_tensor(shape):    \n","    return tf.random.normal(shape,mean=0.0, stddev=1.)*0.01\n","\n","get_normal_tensor((2,5))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6eZA2qrLUyv","colab_type":"code","colab":{}},"source":["tf.random_normal_initializer(mean=0,stddev=1.0)((2,5))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mVtsoIYW7e2_","colab_type":"code","colab":{}},"source":["class RNNCell(object):\n","    def __init__(self,n_x,n_a,w_init_fn):\n","        self.n_x = n_x\n","        self.n_a = n_a\n","        \n","        self.Wax = tf.Variable(w_init_fn((n_a,n_x)),dtype=tf.float32)\n","        self.Waa = tf.Variable(w_init_fn((n_a,n_a)),dtype=tf.float32)\n","        self.b =tf.Variable(tf.zeros((n_a,1)))\n","        \n","\n","    def forward(self,a_prev,x):\n","        logging.info(f\"cell fwd - x:{x}\")\n","        logging.info(f\"cell fwd - x:{x.shape}, a_prev: {a_prev.shape}\")\n","        logging.info(f\"cell fwd - wax:{self.Wax.shape}, waa: {self.Waa.shape}\")\n","        z1 = tf.matmul(self.Wax, x,transpose_a=False,transpose_b=True)\n","        logging.info(f\"cell fwd - z1:{z1.shape}\")\n","        z2 = tf.matmul(self.Waa, a_prev)\n","        logging.info(f\"cell fwd - z2:{z2.shape}\")\n","        a_next = tf.tanh(z1+z2 + self.b) # hidden state\n","        logging.info(f\"cell fwd - a_next:{a_next.shape}\")\n","        return a_next\n","\n","logging.set_verbosity(logging.INFO)\n","x_size = 1\n","cell = RNNCell(x_size,5,get_normal_tensor)\n","\n","\n","# a rnn takes an input of shape : nb_example, nb_timestep, nb_of_feature_per_timestep\n","# in this case we have : nb_example: 2, nb_timestep=3, nb_of_features_per_timestep = 1\n","x= np.array([[1,3,2],[2,1,1]],dtype=np.float32 )\n","logging.info(f\"raw x: {x.shape}\")\n","x=tf.expand_dims(x, axis=-1)\n","logging.info(f\"reshaped x: {x.shape}\")\n","# we call cell on first timestep\n","cell.forward(np.zeros((5,1),dtype=np.float32),x[:,0,:]).numpy()#.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ea-U57-SAgnY","colab_type":"code","colab":{}},"source":["class Model(object):\n","    def __init__(self,n_x, n_a, n_y,w_init=None):\n","        logging.info(f\"model init - n_x:{n_x},n_a:{n_a},n_y:{n_y}\")\n","        if w_init==None:\n","            w_init = get_normal_tensor\n","        self.cell =RNNCell(n_x,n_a,w_init)\n","        self.a0 = tf.zeros((n_a,1),dtype=tf.float32)\n","        self.Wya = tf.Variable(w_init((n_y,n_a)),dtype=tf.float32)\n","        self.by =tf.Variable(tf.zeros((n_y,1)))\n","        self.n_y = n_y\n","\n","\n","    def forward(self,X):\n","        logging.info(f\"model fwd - X: {X.shape}\")\n","        seq_len = X.shape[1]\n","        batch_size=X.shape[0]\n","        logging.info(f\"model fwd - batch_size:{batch_size},seql_len: {seq_len}\")\n","        a = {}\n","        a[-1] = tf.identity(self.a0)\n","        logging.info(f\"model fwd - a[-1]:{a[-1].shape},{self.a0.shape}\")\n","        \n","\n","        #layer 1\n","        X=tf.expand_dims(X, axis=-1)\n","        logging.info(f\"model fwd - X reshaped: {X.shape}\")\n","\n","        # recurrent layer\n","        for t in range(seq_len):\n","            a_next = self.cell.forward(a[t-1],X[:,t,:])\n","            a[t] = a_next\n","        # dense on last item\n","        logit = tf.matmul(self.Wya, a_next,transpose_a=False,transpose_b=False) + self.by\n","        y_hat = logit * 100.0\n","        return y_hat\n","        \n","\n","logging.set_verbosity(logging.INFO)\n","model = Model(1,5,1)\n","x= np.array([[1,3,2],[2,1,1]],dtype=np.float32 )  \n","model.forward(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vg1MMXWgJMa5","colab_type":"code","colab":{}},"source":["def compute_loss(y_pred,y_true):\n","    cce = tf.keras.losses.Huber()\n","    loss= cce(y_true, y_pred)\n","    return loss\n","\n","compute_loss([2.1,2.3,4.2], [2.0,1.9,4.4])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8hIkM9pkXYIF","colab_type":"code","colab":{}},"source":["def train_minibatch(model,X,y_true,learning_rate=5e-5, epoch=1):\n","    optimizer = tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n","    with tf.GradientTape() as t:\n","        current_loss =  compute_loss(model.forward(X), y_true)\n","\n","    tf.summary.scalar('loss', data=current_loss, step=epoch)\n","    dWya, dby, dWax,dWaa,db = t.gradient(current_loss, \n","                                         [model.Wya, model.by,model.cell.Wax, model.cell.Waa,model.cell.b])\n","    \n","    w_g = zip([dWya, dby, dWax,dWaa,db], \n","                                  [model.Wya, model.by,model.cell.Wax, model.cell.Waa,model.cell.b])\n","    optimizer.apply_gradients(w_g)\n","\n","    return current_loss\n","logging.set_verbosity(logging.ERROR)\n","model = Model(1,5,1)\n","x= np.array([[1,3,2],[2,1,1]],dtype=np.float32 ) \n","y_true = np.array([[4],[0]],dtype=np.float32 )   \n","model.forward(x)\n","train_minibatch(model,x,y_true,0.5,1)  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1G0CAX3j_DOn","colab_type":"text"},"source":["## Find the best learning rate\n","\n","Try different learning rates on each epoch and identifies the one that has the lower loss."]},{"cell_type":"code","metadata":{"id":"7kucT6O1XYF4","colab_type":"code","colab":{}},"source":["\n","model = Model(1,40,1)\n","\n","\n","\n","def train(model,train_ds,nb_epochs=100,metric_func=tf.keras.metrics.MeanAbsoluteError(),lr=None, lr_cb=None):\n","    losses =[]\n","    metrics = []\n","    lrs = []\n","    epochs = range(nb_epochs)\n","    \n","    for epoch in epochs:\n","        batch_nb = 0\n","\n","        if not lr_cb==None:\n","            lr = lr_cb.schedule(epoch)\n","        lrs.append(lr)\n","        tf.summary.scalar('learning_rate', data=lr, step=epoch)\n","        for x, y in train_ds:\n","            current_loss = train_minibatch(model, x, y,learning_rate=lr, epoch=epoch)\n","            batch_nb= batch_nb+1\n","\n","        losses.append(current_loss.numpy())\n","        X_train, y_train = next(iter(train_ds))\n","        y_pred_train = model.forward(X_train)\n","        metric = metric_func(y_train,y_pred_train)\n","        metrics.append(metric.numpy())\n","        if epoch % 10 == 0:\n","            print(f\"epoch {epoch} >> lr: {lr}, loss:{current_loss.numpy()},'metric mae:{metric.numpy()}\")\n","\n","    return losses, metrics,lrs\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTsxCRDJFKsc","colab_type":"code","colab":{}},"source":["import datetime \n","import os\n","logdir = \"logs/rnn-timeseries/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n","file_writer.set_as_default()\n","logging.set_verbosity(logging.ERROR)\n","lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch:1e-8 * 10**(epoch / 20))\n","losses, metrics,lrs=train(model, train_ds,nb_epochs=100,lr_cb=lr_schedule)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iyOeOy7Uase3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z4BHFBVO-UO_","colab_type":"text"},"source":["learning rate of 1e-5 "]},{"cell_type":"code","metadata":{"id":"BflZEFU3p1CA","colab_type":"code","colab":{}},"source":["plt.semilogx(lrs, losses)\n","plt.axis([1e-8, 1e-4, 0, 30])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMjNIXdfEysZ","colab_type":"text"},"source":["Learn with lr of 5e-5"]},{"cell_type":"code","metadata":{"id":"SiGDtZq_EvWN","colab_type":"code","colab":{}},"source":["logdir = \"logs/rnn-timeseries/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n","file_writer.set_as_default()\n","\n","logging.set_verbosity(logging.ERROR)\n","losses, metrics,lrs=train(model, train_ds,nb_epochs=100,lr=1e-5)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDolTz_EXYDD","colab_type":"code","colab":{}},"source":["forecast=[]\n","for time in range(len(series) - window_size):\n","    forecast.append(model.forward(series[time:time + window_size][np.newaxis]))\n","\n","forecast = forecast[split_time-window_size:]\n","results = np.array(forecast)[:, 0, 0]\n","\n","\n","plt.figure(figsize=(10, 6))\n","\n","plot_series(time_test, x_test)\n","plot_series(time_test, results,color='red')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E7Nj_XeAktoU","colab_type":"text"},"source":["## Keras version"]},{"cell_type":"code","metadata":{"id":"1-E8XAz9fLO8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJtiKefAl8lQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"64C_nDb6p3SB","colab_type":"code","colab":{}},"source":["\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Input(shape=(window_size)),\n","    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1)),\n","    # 5 is a too small hidden state -> use 40.\n","    tf.keras.layers.SimpleRNN(10, return_sequences=True),\n","    tf.keras.layers.SimpleRNN(10),\n","    tf.keras.layers.Dense(1),\n","    tf.keras.layers.Lambda(lambda x: x*100.0)\n","    ])\n","\n","optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n","#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n","model.compile(optimizer=optimizer,\n","              loss=tf.keras.losses.Huber(),\n","              metrics=['mae'])\n","\n","#model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PTW44brelttc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQaEdvQSdAQP","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()\n","log_dir=\"logs/keras-rnn-timeseries/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n","\n","model.fit(train_ds, epochs=100, callbacks=[tensorboard_cb])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uTUZAib4ns6R","colab_type":"code","colab":{}},"source":["model.weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKVfXxRkwr-B","colab_type":"code","colab":{}},"source":["%tensorboard --logdir logs/keras-rnn-timeseries"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOIclk5tdpBw","colab_type":"code","colab":{}},"source":["forecast=[]\n","for time in range(len(series) - window_size):\n","    forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n","\n","forecast = forecast[split_time-window_size:]\n","results = np.array(forecast)[:, 0, 0]\n","\n","\n","plt.figure(figsize=(10, 6))\n","\n","plot_series(time_test, x_test)\n","plot_series(time_test, results,color='red')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qKKoG1iPo4ub","colab_type":"text"},"source":["Trash"]},{"cell_type":"code","metadata":{"id":"f02KwBv3kR4a","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"txlKu80UhWv1","colab_type":"code","colab":{}},"source":["def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","  series = np.expand_dims(series, axis=1)\n","  #print(series)\n","  dataset = tf.data.Dataset.from_tensor_slices(series)\n","  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n","  #print(\"window:\",list(next(iter(dataset)).as_numpy_iterator()) )\n","  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n","  #print(\"flat_map:\",list(dataset.as_numpy_iterator()) )\n","\n","  dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n","  #print(\"map:\",list(dataset.as_numpy_iterator()) )\n","  dataset = dataset.shuffle(shuffle_buffer)\n","  dataset = dataset.batch(batch_size,drop_remainder=True)\n","  return dataset\n","\n","tmp_x= np.array([1,3,2,4,6,2,1,1,2,1,6,7,2,4,6],dtype=np.float32 )\n","tmp_set = windowed_dataset(tmp_x, window_size=3, batch_size=4, shuffle_buffer=15)\n","#iter = iter(tmp_set)\n","#next(iter)#, next(iter) \n","next(iter(tmp_set))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"utbBQvt8iU6_","colab_type":"code","colab":{}},"source":["window_size = 20\n","batch_size = 32\n","\n","\n","train_ds = windowed_dataset(x_train, window_size, batch_size=128, shuffle_buffer= train_nb)\n","test_ds = windowed_dataset(x_test, window_size, batch_size=128, shuffle_buffer= test_nb)"],"execution_count":0,"outputs":[]}]}